{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo Tree Search (MCTS)\n",
    "This is an agent that plays with UCT-MCTS.  \n",
    "Code is highly commented to be readable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading environment lux_ai_2022 failed: No module named 'vec_noise'\n"
     ]
    }
   ],
   "source": [
    "# ConnectX environment was defined in v0.1.6\n",
    "from kaggle_environments import evaluate, make, utils\n",
    "import random\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create ConnectX Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episodeSteps': 1000, 'actTimeout': 2, 'runTimeout': 1200, 'columns': 7, 'rows': 6, 'inarow': 4, 'agentTimeout': 60, 'timeout': 2}\n"
     ]
    }
   ],
   "source": [
    "env = make(\"connectx\", debug=True)\n",
    "configuration = env.configuration\n",
    "print(configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make drawScore parameter in configuration?\n",
    "configuration.drawScore = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episodeSteps': 1000, 'actTimeout': 2, 'runTimeout': 1200, 'columns': 7, 'rows': 6, 'inarow': 4, 'agentTimeout': 60, 'timeout': 2, 'drawScore': 0.5}\n"
     ]
    }
   ],
   "source": [
    "print(configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episodeSteps': 1000, 'actTimeout': 2, 'runTimeout': 1200, 'columns': 7, 'rows': 6, 'inarow': 4, 'agentTimeout': 60, 'timeout': 2}\n"
     ]
    }
   ],
   "source": [
    "configuration.pop('drawScore')\n",
    "print(configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MCTS_agent(observation, configuration):\n",
    "    \"\"\"\n",
    "    Connect X agent based on MCTS.\n",
    "    \"\"\"\n",
    "    import random\n",
    "    import math\n",
    "    import time\n",
    "    global current_state  # so tree can be recycled\n",
    "\n",
    "    init_time = time.time()\n",
    "    EMPTY = 0\n",
    "    T_max = configuration.timeout # time per move, left some overhead - RWM, old offset -0.34\n",
    "    Cp_default = 1\n",
    "\n",
    "    # RWM new variable for possible tuning\n",
    "    # try:\n",
    "    #     drawScore = configuration['drawScore']\n",
    "    #     configuration.pop('drawScore')\n",
    "    # except:\n",
    "    #     drawScore = 0.5\n",
    "    # else:\n",
    "    #     drawScore = configuration['drawScore']\n",
    "    #     configuration.pop('drawScore')\n",
    "\n",
    "    def play(board, column, mark, config):\n",
    "        \"\"\" Plays a move. Taken from the Kaggle environment. \"\"\"\n",
    "        columns = config.columns\n",
    "        rows = config.rows\n",
    "        row = max([r for r in range(rows) if board[column + (r * columns)] == EMPTY])\n",
    "        board[column + (row * columns)] = mark\n",
    "\n",
    "    def is_win(board, column, mark, config):\n",
    "        \"\"\" Checks for a win. Taken from the Kaggle environment. \"\"\"\n",
    "        columns = config.columns\n",
    "        rows = config.rows\n",
    "\n",
    "        # RWM edit\n",
    "        inarow = config.inarow - 1\n",
    "\n",
    "        # Connect3 to speed up testing?\n",
    "        # inarow = 3 - 1\n",
    "\n",
    "        row = min([r for r in range(rows) if board[column + (r * columns)] == mark])\n",
    "\n",
    "        def count(offset_row, offset_column):\n",
    "            for i in range(1, inarow + 1):\n",
    "                r = row + offset_row * i\n",
    "                c = column + offset_column * i\n",
    "                if (\n",
    "                        r < 0\n",
    "                        or r >= rows\n",
    "                        or c < 0\n",
    "                        or c >= columns\n",
    "                        or board[c + (r * columns)] != mark\n",
    "                ):\n",
    "                    return i - 1\n",
    "            return inarow\n",
    "\n",
    "        return (\n",
    "                count(1, 0) >= inarow  # vertical.\n",
    "                or (count(0, 1) + count(0, -1)) >= inarow  # horizontal.\n",
    "                or (count(-1, -1) + count(1, 1)) >= inarow  # top left diagonal.\n",
    "                or (count(-1, 1) + count(1, -1)) >= inarow  # top right diagonal.\n",
    "        )\n",
    "\n",
    "    def is_tie(board):\n",
    "        \"\"\" Checks if a tie occured. \"\"\"\n",
    "        return not(any(mark == EMPTY for mark in board))\n",
    "\n",
    "    def check_finish_and_score(board, column, mark, config, drawScore):\n",
    "        \"\"\" Returns a tuple where the first argument states whether game is finished and second argument returns score if game has finished. \"\"\"\n",
    "        if is_win(board, column, mark, config):\n",
    "            return (True, 1)\n",
    "        if is_tie(board):\n",
    "            # RWM - default tie score = 0.5 - what if we change this? ie, punish draws to promote aggressive play?\n",
    "            return (True, drawScore)\n",
    "        else:\n",
    "            return (False, None)\n",
    "\n",
    "    def uct_score(node_total_score, node_total_visits, parent_total_visits, Cp=Cp_default):\n",
    "        \"\"\" UCB1 calculation. \"\"\"\n",
    "        if node_total_visits == 0:\n",
    "            return math.inf\n",
    "        return node_total_score / node_total_visits + Cp * math.sqrt(\n",
    "            2 * math.log(parent_total_visits) / node_total_visits)\n",
    "\n",
    "    def opponent_mark(mark):\n",
    "        \"\"\" The mark indicates which player is active - player 1 or player 2. \"\"\"\n",
    "        return 3 - mark\n",
    "\n",
    "    def opponent_score(score):\n",
    "        \"\"\" To backpropagate scores on the tree. \"\"\"\n",
    "        return 1 - score\n",
    "\n",
    "    def random_action(board, config):\n",
    "        \"\"\" Returns a random legal action (from the open columns). \"\"\"\n",
    "        return random.choice([c for c in range(config.columns) if board[c] == EMPTY])\n",
    "\n",
    "    def default_policy_simulation(board, mark, config, drawScore):\n",
    "        \"\"\"\n",
    "        Run a random play simulation. Starting state is assumed to be a non-terminal state.\n",
    "        Returns score of the game for the player with the given mark.\n",
    "        \"\"\"\n",
    "        original_mark = mark\n",
    "        board = board.copy()\n",
    "        column = random_action(board, config)\n",
    "        play(board, column, mark, config)\n",
    "        is_finish, score = check_finish_and_score(board, column, mark, config, drawScore)\n",
    "        while not is_finish:\n",
    "            mark = opponent_mark(mark)\n",
    "            column = random_action(board, config)\n",
    "            play(board, column, mark, config)\n",
    "            is_finish, score = check_finish_and_score(board, column, mark, config, drawScore)\n",
    "        if mark == original_mark:\n",
    "            return score\n",
    "        return opponent_score(score)\n",
    "    \n",
    "    def find_action_taken_by_opponent(new_board, old_board, config):\n",
    "        \"\"\" Given a new board state and a previous one, finds which move was taken. Used for recycling tree between moves. \"\"\"\n",
    "        for i, piece in enumerate(new_board):\n",
    "            if piece != old_board[i]:\n",
    "                return i % config.columns\n",
    "        return -1  # shouldn't get here\n",
    "\n",
    "    class State():\n",
    "        \"\"\" \n",
    "        A class that represents nodes in the game tree.\n",
    "        \n",
    "        \"\"\"\n",
    "        def __init__(self, board, mark, config, parent=None, is_terminal=False, terminal_score=None, action_taken=None):\n",
    "            self.board = board.copy()\n",
    "            self.mark = mark\n",
    "            self.config = config\n",
    "            self.children = []\n",
    "            self.parent = parent\n",
    "            self.node_total_score = 0\n",
    "            self.node_total_visits = 0\n",
    "            self.available_moves = [c for c in range(config.columns) if board[c] == EMPTY]\n",
    "            self.expandable_moves = self.available_moves.copy()\n",
    "            self.is_terminal = is_terminal\n",
    "            self.terminal_score = terminal_score\n",
    "            self.action_taken = action_taken\n",
    "\n",
    "            # drawScore brought in here\n",
    "            try:\n",
    "                self.drawScore = config['drawScore']\n",
    "            except:\n",
    "                self.drawScore = 0.5\n",
    "            else:\n",
    "                self.drawScore = config['drawScore']\n",
    "\n",
    "        def is_expandable(self):\n",
    "            \"\"\" Checks if the node has unexplored children. \"\"\"\n",
    "            return (not self.is_terminal) and (len(self.expandable_moves) > 0)\n",
    "\n",
    "        def expand_and_simulate_child(self):\n",
    "            \"\"\" Expands a random move from the legal unexplored moves, and runs a simulation of it \n",
    "            (Expansion + Simulation + Backpropagation stages in the MCTS algorithm description). \"\"\"\n",
    "            column = random.choice(self.expandable_moves)\n",
    "            child_board = self.board.copy()\n",
    "            play(child_board, column, self.mark, self.config)\n",
    "            is_terminal, terminal_score = check_finish_and_score(child_board, column, self.mark, self.config, self.drawScore)\n",
    "            self.children.append(State(child_board, opponent_mark(self.mark),\n",
    "                                       self.config, parent=self,\n",
    "                                       is_terminal=is_terminal,\n",
    "                                       terminal_score=terminal_score,\n",
    "                                       action_taken=column\n",
    "                                       ))\n",
    "            simulation_score = self.children[-1].simulate()\n",
    "            self.children[-1].backpropagate(simulation_score)\n",
    "            self.expandable_moves.remove(column)\n",
    "\n",
    "        def choose_strongest_child(self, Cp):\n",
    "            \"\"\"\n",
    "            Chooses child that maximizes UCB1 score (Selection stage in the MCTS algorithm description).\n",
    "            \"\"\"\n",
    "            children_scores = [uct_score(child.node_total_score,\n",
    "                                         child.node_total_visits,\n",
    "                                         self.node_total_visits,\n",
    "                                         Cp) for child in self.children]\n",
    "            max_score = max(children_scores)\n",
    "            best_child_index = children_scores.index(max_score)\n",
    "            return self.children[best_child_index]\n",
    "            \n",
    "        def choose_play_child(self):\n",
    "            \"\"\" Choose child with maximum total score.\"\"\"\n",
    "            children_scores = [child.node_total_score for child in self.children]\n",
    "            max_score = max(children_scores)\n",
    "            best_child_index = children_scores.index(max_score)\n",
    "            return self.children[best_child_index]\n",
    "\n",
    "        def tree_single_run(self):\n",
    "            \"\"\"\n",
    "            A single iteration of the 4 stages of the MCTS algorithm.\n",
    "            \"\"\"\n",
    "            if self.is_terminal:\n",
    "                self.backpropagate(self.terminal_score)\n",
    "                return\n",
    "            if self.is_expandable():\n",
    "                self.expand_and_simulate_child()\n",
    "                return\n",
    "            self.choose_strongest_child(Cp_default).tree_single_run()\n",
    "\n",
    "        def simulate(self):\n",
    "            \"\"\"\n",
    "            Runs a simulation from the current state. \n",
    "            This method is used to simulate a game after move of current player, so if a terminal state was reached,\n",
    "            the score would belong to the current player who made the move.\n",
    "            But otherwise the score received from the simulation run is the opponent's score and thus needs to be flipped with the function opponent_score().            \n",
    "            \"\"\"\n",
    "            if self.is_terminal:\n",
    "                return self.terminal_score\n",
    "            return opponent_score(default_policy_simulation(self.board, self.mark, self.config, self.drawScore))\n",
    "\n",
    "        def backpropagate(self, simulation_score):\n",
    "            \"\"\"\n",
    "            Backpropagates score and visit count to parents.\n",
    "            \"\"\"\n",
    "            self.node_total_score += simulation_score\n",
    "            self.node_total_visits += 1\n",
    "            if self.parent is not None:\n",
    "                self.parent.backpropagate(opponent_score(simulation_score))\n",
    "                \n",
    "        def choose_child_via_action(self, action):\n",
    "            \"\"\" Choose child given the action taken from the state. Used for recycling of tree. \"\"\"\n",
    "            for child in self.children:\n",
    "                if child.action_taken == action:\n",
    "                    return child\n",
    "            return None\n",
    "\n",
    "    board = observation.board\n",
    "    mark = observation.mark\n",
    "    \n",
    "    # If current_state already exists, recycle it based on action taken by opponent\n",
    "    try:  \n",
    "        current_state = current_state.choose_child_via_action(\n",
    "            find_action_taken_by_opponent(board, current_state.board, configuration, drawScore))\n",
    "        current_state.parent = None  # make current_state the root node, dereference parents and siblings\n",
    "        \n",
    "    except:  # new game or other error in recycling attempt due to Kaggle mechanism\n",
    "        current_state = State(board, mark,  # This state is considered after the opponent's move\n",
    "                              configuration, parent=None, is_terminal=False, terminal_score=None, action_taken=None)\n",
    "   \n",
    "    # Run MCTS iterations until time limit is reached.\n",
    "    while time.time() - init_time <= T_max:\n",
    "        current_state.tree_single_run()\n",
    "        \n",
    "    current_state = current_state.choose_play_child()\n",
    "    return current_state.action_taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episodeSteps': 1000, 'actTimeout': 2, 'runTimeout': 1200, 'columns': 7, 'rows': 6, 'inarow': 4, 'agentTimeout': 60, 'timeout': 2}\n"
     ]
    }
   ],
   "source": [
    "print(configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check agent validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "# ORIGINAL\n",
    "env.reset()\n",
    "try:\n",
    "    del current_state\n",
    "except:\n",
    "    pass\n",
    "\n",
    "env.run([MCTS_agent, MCTS_agent])\n",
    "print(\"Success!\" if env.state[0].status == env.state[1].status == \"DONE\" else \"Failed...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episodeSteps': 1000, 'actTimeout': 2, 'runTimeout': 1200, 'columns': 7, 'rows': 6, 'inarow': 4, 'agentTimeout': 60, 'timeout': 2, 'drawScore': 0.1}\n"
     ]
    }
   ],
   "source": [
    "configuration.drawScore = 0.1\n",
    "print(configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'episodeSteps': 1000,\n",
       " 'actTimeout': 2,\n",
       " 'runTimeout': 1200,\n",
       " 'columns': 7,\n",
       " 'rows': 6,\n",
       " 'inarow': 4,\n",
       " 'agentTimeout': 60,\n",
       " 'timeout': 2,\n",
       " 'drawScore': 0.1}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env config check drawScore = 0.1\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "# drawScore added\n",
    "env.reset()\n",
    "try:\n",
    "    del current_state\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(\"Env config check drawScore =\", env.configuration.drawScore)\n",
    "\n",
    "env.run([MCTS_agent, MCTS_agent])\n",
    "print(\"Success!\" if env.state[0].status == env.state[1].status == \"DONE\" else \"Failed...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate your agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, -1]]\n",
      "TEST - Random vs Random: Score = 1.0, N = 1, losses = 0\n",
      "[[1, -1]]\n",
      "My Agent vs Random Agent: Score = 1.0, N = 1, losses = 0\n"
     ]
    }
   ],
   "source": [
    "# ORIGINAL\n",
    "# RWM edit - kept dividing by zero...\n",
    "# -1 = always loss, +1 = always win, ~0 = evens\n",
    "\n",
    "configuration.pop('drawScore')\n",
    "\n",
    "def mean_reward(rewards):\n",
    "    print(rewards)\n",
    "    \n",
    "    avg = sum(r[0] for r in rewards) / len(rewards)\n",
    "    num_losses = sum(-r[0] for r in rewards if r[0] == -1)\n",
    "\n",
    "    print_string = f\"Score = {avg}, N = {len(rewards)}, losses = {num_losses}\"\n",
    "\n",
    "    return print_string, avg\n",
    "\n",
    "# Run multiple episodes to estimate its performance.\n",
    "iterations = 1\n",
    "\n",
    "# RWM tests\n",
    "# print(\"BENCHMARK - Negamax vs Random:\", mean_reward(evaluate(\"connectx\", [\"negamax\", \"random\"], num_episodes = iterations))[0])\n",
    "print(\"TEST - Random vs Random:\", mean_reward(evaluate(\"connectx\", [\"random\", \"random\"], num_episodes = iterations))[0])\n",
    "\n",
    "# RWM edit, old = 20 20 5 5\n",
    "\n",
    "print(\"My Agent vs Random Agent:\", mean_reward(evaluate(\"connectx\", [MCTS_agent, \"random\"], num_episodes = iterations))[0])\n",
    "# print(\"Random Agent vs My Agent:\", mean_reward(evaluate(\"connectx\", [\"random\", MCTS_agent], num_episodes = iterations))[0])\n",
    "# print(\"My Agent vs Negamax Agent:\", mean_reward(evaluate(\"connectx\", [MCTS_agent, \"negamax\"], num_episodes = iterations))[0])\n",
    "# print(\"Negamax Agent vs My Agent:\", mean_reward(evaluate(\"connectx\", [\"negamax\", MCTS_agent], num_episodes = iterations))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1, 1]]\n",
      "TEST - Random vs Random: Score = -1.0, N = 1, losses = 1\n",
      "[[1, -1]]\n",
      "My Agent vs Random Agent: Score = 1.0, N = 1, losses = 0\n"
     ]
    }
   ],
   "source": [
    "# drawScore = 0.5 added\n",
    "\n",
    "configuration.drawScore = 0.5\n",
    "\n",
    "def mean_reward(rewards):\n",
    "    print(rewards)\n",
    "    \n",
    "    avg = sum(r[0] for r in rewards) / len(rewards)\n",
    "    num_losses = sum(-r[0] for r in rewards if r[0] == -1)\n",
    "\n",
    "    print_string = f\"Score = {avg}, N = {len(rewards)}, losses = {num_losses}\"\n",
    "\n",
    "    return print_string, avg\n",
    "\n",
    "# Run multiple episodes to estimate its performance.\n",
    "iterations = 1\n",
    "\n",
    "# RWM tests\n",
    "# print(\"BENCHMARK - Negamax vs Random:\", mean_reward(evaluate(\"connectx\", [\"negamax\", \"random\"], num_episodes = iterations))[0])\n",
    "print(\"TEST - Random vs Random:\", mean_reward(evaluate(\"connectx\", [\"random\", \"random\"], num_episodes = iterations))[0])\n",
    "\n",
    "# RWM edit, old = 20 20 5 5\n",
    "\n",
    "print(\"My Agent vs Random Agent:\", mean_reward(evaluate(\"connectx\", [MCTS_agent, \"random\"], num_episodes = iterations))[0])\n",
    "# print(\"Random Agent vs My Agent:\", mean_reward(evaluate(\"connectx\", [\"random\", MCTS_agent], num_episodes = iterations))[0])\n",
    "# print(\"My Agent vs Negamax Agent:\", mean_reward(evaluate(\"connectx\", [MCTS_agent, \"negamax\"], num_episodes = iterations))[0])\n",
    "# print(\"Negamax Agent vs My Agent:\", mean_reward(evaluate(\"connectx\", [\"negamax\", MCTS_agent], num_episodes = iterations))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, -1]]\n",
      "TEST - Random vs Random: Score = 1.0, N = 1, losses = 0\n",
      "[[1, -1]]\n",
      "My Agent vs Random Agent: Score = 1.0, N = 1, losses = 0\n"
     ]
    }
   ],
   "source": [
    "# drawScore = 0.1 added \n",
    "# RWM edit - kept dividing by zero...\n",
    "# -1 = always loss, +1 = always win, ~0 = evens\n",
    "\n",
    "configuration.drawScore = 0.1\n",
    "\n",
    "def mean_reward(rewards):\n",
    "    print(rewards)\n",
    "    \n",
    "    avg = sum(r[0] for r in rewards) / len(rewards)\n",
    "    num_losses = sum(-r[0] for r in rewards if r[0] == -1)\n",
    "\n",
    "    print_string = f\"Score = {avg}, N = {len(rewards)}, losses = {num_losses}\"\n",
    "\n",
    "    return print_string, avg\n",
    "\n",
    "# Run multiple episodes to estimate its performance.\n",
    "iterations = 1\n",
    "\n",
    "# RWM tests\n",
    "# print(\"BENCHMARK - Negamax vs Random:\", mean_reward(evaluate(\"connectx\", [\"negamax\", \"random\"], num_episodes = iterations))[0])\n",
    "print(\"TEST - Random vs Random:\", mean_reward(evaluate(\"connectx\", [\"random\", \"random\"], num_episodes = iterations))[0])\n",
    "\n",
    "# RWM edit, old = 20 20 5 5\n",
    "\n",
    "print(\"My Agent vs Random Agent:\", mean_reward(evaluate(\"connectx\", [MCTS_agent, \"random\"], num_episodes = iterations))[0])\n",
    "# print(\"Random Agent vs My Agent:\", mean_reward(evaluate(\"connectx\", [\"random\", MCTS_agent], num_episodes = iterations))[0])\n",
    "# print(\"My Agent vs Negamax Agent:\", mean_reward(evaluate(\"connectx\", [MCTS_agent, \"negamax\"], num_episodes = iterations))[0])\n",
    "# print(\"Negamax Agent vs My Agent:\", mean_reward(evaluate(\"connectx\", [\"negamax\", MCTS_agent], num_episodes = iterations))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, -1], [1, -1], [1, -1], [1, -1], [1, -1], [1, -1], [1, -1], [1, -1], [1, -1], [1, -1]]\n",
      "My Agent vs Negamax Agent: Score = 1.0, N = 10, losses = 0\n"
     ]
    }
   ],
   "source": [
    "# win rate vs draw Score for MCTS vs NEGAMAX\n",
    "\n",
    "for drawScoreTest in [0.1, 0.25, 0.5, 0.75, 0.9]:\n",
    "    configuration.drawScore = drawScoreTest\n",
    "\n",
    "    # Run multiple episodes to estimate its performance.\n",
    "    iterations = 10\n",
    "    \n",
    "    print(\"My Agent vs Negamax Agent:\", mean_reward(evaluate(\"connectx\", [MCTS_agent, \"negamax\"], num_episodes = iterations))[0])\n",
    "    print(\"Negamax Agent vs My Agent:\", mean_reward(evaluate(\"connectx\", [\"negamax\", MCTS_agent], num_episodes = iterations))[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
