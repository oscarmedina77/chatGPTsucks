{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo Tree Search (MCTS)\n",
    "This is an agent that plays with UCT-MCTS.  \n",
    "Code is highly commented to be readable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# ConnectX environment was defined in v0.1.6\n",
    "from kaggle_environments import evaluate, make, utils\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "# RWM added\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create ConnectX Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "env = make(\"connectx\", debug=True)\n",
    "configuration = env.configuration\n",
    "print(configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MCTS_agent(observation, configuration):\n",
    "    \"\"\"\n",
    "    Connect X agent based on MCTS.\n",
    "    \"\"\"\n",
    "    import random\n",
    "    import math\n",
    "    import time\n",
    "    global current_state  # so tree can be recycled\n",
    "\n",
    "    init_time = time.time()\n",
    "    EMPTY = 0\n",
    "    T_max = configuration.timeout # time per move, left some overhead - RWM, old offset -0.34\n",
    "    Cp_default = 1\n",
    "\n",
    "    def play(board, column, mark, config):\n",
    "        \"\"\" Plays a move. Taken from the Kaggle environment. \"\"\"\n",
    "        columns = config.columns\n",
    "        rows = config.rows\n",
    "        row = max([r for r in range(rows) if board[column + (r * columns)] == EMPTY])\n",
    "        board[column + (row * columns)] = mark\n",
    "\n",
    "    def is_win(board, column, mark, config):\n",
    "        \"\"\" Checks for a win. Taken from the Kaggle environment. \"\"\"\n",
    "        columns = config.columns\n",
    "        rows = config.rows\n",
    "\n",
    "        # RWM edit\n",
    "        inarow = config.inarow - 1\n",
    "\n",
    "        # Connect3 to speed up testing?\n",
    "        # inarow = 3 - 1\n",
    "\n",
    "        row = min([r for r in range(rows) if board[column + (r * columns)] == mark])\n",
    "\n",
    "        def count(offset_row, offset_column):\n",
    "            for i in range(1, inarow + 1):\n",
    "                r = row + offset_row * i\n",
    "                c = column + offset_column * i\n",
    "                if (\n",
    "                        r < 0\n",
    "                        or r >= rows\n",
    "                        or c < 0\n",
    "                        or c >= columns\n",
    "                        or board[c + (r * columns)] != mark\n",
    "                ):\n",
    "                    return i - 1\n",
    "            return inarow\n",
    "\n",
    "        return (\n",
    "                count(1, 0) >= inarow  # vertical.\n",
    "                or (count(0, 1) + count(0, -1)) >= inarow  # horizontal.\n",
    "                or (count(-1, -1) + count(1, 1)) >= inarow  # top left diagonal.\n",
    "                or (count(-1, 1) + count(1, -1)) >= inarow  # top right diagonal.\n",
    "        )\n",
    "\n",
    "    def is_tie(board):\n",
    "        \"\"\" Checks if a tie occured. \"\"\"\n",
    "        return not(any(mark == EMPTY for mark in board))\n",
    "\n",
    "    def check_finish_and_score(board, column, mark, config):\n",
    "        \"\"\" Returns a tuple where the first argument states whether game is finished and second argument returns score if game has finished. \"\"\"\n",
    "        if is_win(board, column, mark, config):\n",
    "            return (True, 1)\n",
    "        if is_tie(board):\n",
    "            # RWM - default tie score = 0.5 - what if we change this? ie, punish draws to promote aggressive play?\n",
    "            return (True, 0.1)\n",
    "        else:\n",
    "            return (False, None)\n",
    "\n",
    "    def uct_score(node_total_score, node_total_visits, parent_total_visits, Cp=Cp_default):\n",
    "        \"\"\" UCB1 calculation. \"\"\"\n",
    "        if node_total_visits == 0:\n",
    "            return math.inf\n",
    "        return node_total_score / node_total_visits + Cp * math.sqrt(\n",
    "            2 * math.log(parent_total_visits) / node_total_visits)\n",
    "\n",
    "    def opponent_mark(mark):\n",
    "        \"\"\" The mark indicates which player is active - player 1 or player 2. \"\"\"\n",
    "        return 3 - mark\n",
    "\n",
    "    def opponent_score(score):\n",
    "        \"\"\" To backpropagate scores on the tree. \"\"\"\n",
    "        return 1 - score\n",
    "\n",
    "    def random_action(board, config):\n",
    "        \"\"\" Returns a random legal action (from the open columns). \"\"\"\n",
    "        return random.choice([c for c in range(config.columns) if board[c] == EMPTY])\n",
    "\n",
    "    def default_policy_simulation(board, mark, config):\n",
    "        \"\"\"\n",
    "        Run a random play simulation. Starting state is assumed to be a non-terminal state.\n",
    "        Returns score of the game for the player with the given mark.\n",
    "        \"\"\"\n",
    "        original_mark = mark\n",
    "        board = board.copy()\n",
    "        column = random_action(board, config)\n",
    "        play(board, column, mark, config)\n",
    "        is_finish, score = check_finish_and_score(board, column, mark, config)\n",
    "        while not is_finish:\n",
    "            mark = opponent_mark(mark)\n",
    "            column = random_action(board, config)\n",
    "            play(board, column, mark, config)\n",
    "            is_finish, score = check_finish_and_score(board, column, mark, config)\n",
    "        if mark == original_mark:\n",
    "            return score\n",
    "        return opponent_score(score)\n",
    "    \n",
    "    def find_action_taken_by_opponent(new_board, old_board, config):\n",
    "        \"\"\" Given a new board state and a previous one, finds which move was taken. Used for recycling tree between moves. \"\"\"\n",
    "        for i, piece in enumerate(new_board):\n",
    "            if piece != old_board[i]:\n",
    "                return i % config.columns\n",
    "        return -1  # shouldn't get here\n",
    "\n",
    "    class State():\n",
    "        \"\"\" \n",
    "        A class that represents nodes in the game tree.\n",
    "        \n",
    "        \"\"\"\n",
    "        def __init__(self, board, mark, config, parent=None, is_terminal=False, terminal_score=None, action_taken=None):\n",
    "            self.board = board.copy()\n",
    "            self.mark = mark\n",
    "            self.config = config\n",
    "            self.children = []\n",
    "            self.parent = parent\n",
    "            self.node_total_score = 0\n",
    "            self.node_total_visits = 0\n",
    "            self.available_moves = [c for c in range(config.columns) if board[c] == EMPTY]\n",
    "            self.expandable_moves = self.available_moves.copy()\n",
    "            self.is_terminal = is_terminal\n",
    "            self.terminal_score = terminal_score \n",
    "            self.action_taken = action_taken\n",
    "\n",
    "        def is_expandable(self):\n",
    "            \"\"\" Checks if the node has unexplored children. \"\"\"\n",
    "            return (not self.is_terminal) and (len(self.expandable_moves) > 0)\n",
    "\n",
    "        def expand_and_simulate_child(self):\n",
    "            \"\"\" Expands a random move from the legal unexplored moves, and runs a simulation of it \n",
    "            (Expansion + Simulation + Backpropagation stages in the MCTS algorithm description). \"\"\"\n",
    "            column = random.choice(self.expandable_moves)\n",
    "            child_board = self.board.copy()\n",
    "            play(child_board, column, self.mark, self.config)\n",
    "            is_terminal, terminal_score = check_finish_and_score(child_board, column, self.mark, self.config)\n",
    "            self.children.append(State(child_board, opponent_mark(self.mark),\n",
    "                                       self.config, parent=self,\n",
    "                                       is_terminal=is_terminal,\n",
    "                                       terminal_score=terminal_score,\n",
    "                                       action_taken=column\n",
    "                                       ))\n",
    "\n",
    "\n",
    "            simulation_score = self.children[-1].simulate()\n",
    "            self.children[-1].backpropagate(simulation_score)\n",
    "\n",
    "            \n",
    "            self.expandable_moves.remove(column)\n",
    "\n",
    "        def choose_strongest_child(self, Cp):\n",
    "            \"\"\"\n",
    "            Chooses child that maximizes UCB1 score (Selection stage in the MCTS algorithm description).\n",
    "            \"\"\"\n",
    "            children_scores = [uct_score(child.node_total_score,\n",
    "                                         child.node_total_visits,\n",
    "                                         self.node_total_visits,\n",
    "                                         Cp) for child in self.children]\n",
    "            max_score = max(children_scores)\n",
    "            best_child_index = children_scores.index(max_score)\n",
    "            return self.children[best_child_index]\n",
    "            \n",
    "        def choose_play_child(self):\n",
    "            \"\"\" Choose child with maximum total score.\"\"\"\n",
    "            children_scores = [child.node_total_score for child in self.children]\n",
    "            max_score = max(children_scores)\n",
    "            best_child_index = children_scores.index(max_score)\n",
    "            return self.children[best_child_index]\n",
    "\n",
    "        def tree_single_run(self):\n",
    "            \"\"\"\n",
    "            A single iteration of the 4 stages of the MCTS algorithm.\n",
    "            \"\"\"\n",
    "            if self.is_terminal:\n",
    "                self.backpropagate(self.terminal_score)\n",
    "                return\n",
    "            if self.is_expandable():\n",
    "                self.expand_and_simulate_child()\n",
    "                return\n",
    "                \n",
    "            self.choose_strongest_child(Cp_default).tree_single_run()\n",
    "\n",
    "        def simulate(self):\n",
    "            \"\"\"\n",
    "            Runs a simulation from the current state. \n",
    "            This method is used to simulate a game after move of current player, so if a terminal state was reached,\n",
    "            the score would belong to the current player who made the move.\n",
    "            But otherwise the score received from the simulation run is the opponent's score and thus needs to be flipped with the function opponent_score().            \n",
    "            \"\"\"\n",
    "            if self.is_terminal:\n",
    "                return self.terminal_score\n",
    "            return opponent_score(default_policy_simulation(self.board, self.mark, self.config))\n",
    "\n",
    "        def backpropagate(self, simulation_score):\n",
    "            \"\"\"\n",
    "            Backpropagates score and visit count to parents.\n",
    "            \"\"\"\n",
    "            self.node_total_score += simulation_score\n",
    "            self.node_total_visits += 1\n",
    "            if self.parent is not None:\n",
    "                self.parent.backpropagate(opponent_score(simulation_score))\n",
    "                \n",
    "        def choose_child_via_action(self, action):\n",
    "            \"\"\" Choose child given the action taken from the state. Used for recycling of tree. \"\"\"\n",
    "\n",
    "            for child in self.children:\n",
    "                \n",
    "                # RWM test\n",
    "                print(\"child\", child)\n",
    "\n",
    "                if child.action_taken == action:\n",
    "                    return child\n",
    "            return None\n",
    "\n",
    "    board = observation.board\n",
    "    mark = observation.mark\n",
    "    \n",
    "    print(\"observation:\", observation)\n",
    "    print(\"board:\", board)\n",
    "    print(\"mark:\", mark)\n",
    "    print(\"config:\", configuration)\n",
    "    \n",
    "\n",
    "    # If current_state already exists, recycle it based on action taken by opponent\n",
    "    try:  \n",
    "        current_state = current_state.choose_child_via_action(\n",
    "            find_action_taken_by_opponent(board, current_state.board, configuration))\n",
    "        current_state.parent = None  # make current_state the root node, dereference parents and siblings\n",
    "        \n",
    "    except:  # new game or other error in recycling attempt due to Kaggle mechanism\n",
    "        current_state = State(board, mark,  # This state is considered after the opponent's move\n",
    "                              configuration, parent=None, is_terminal=False, terminal_score=None, action_taken=None)\n",
    "   \n",
    "    # Run MCTS iterations until time limit is reached.\n",
    "    loopIndex = 0\n",
    "    while time.time() - init_time <= T_max:\n",
    "        loopIndex += 1\n",
    "        current_state.tree_single_run()\n",
    "    print(\"*58\")\n",
    "    print(\"loopIndex =\", loopIndex)\n",
    "    print(\"*58\")\n",
    "        \n",
    "    current_state = current_state.choose_play_child()\n",
    "    return current_state.action_taken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check agent validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation: {'remainingOverageTime': 59.999865, 'step': 4, 'board': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 1, 2, 0], 'mark': 1}\n",
      "board: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 1, 2, 0]\n",
      "mark: 1\n",
      "config: {'episodeSteps': 1000, 'actTimeout': 2, 'runTimeout': 1200, 'columns': 7, 'rows': 6, 'inarow': 4, 'agentTimeout': 60, 'timeout': 2}\n",
      "child <__main__.MCTS_agent.<locals>.State object at 0x11da38dc0>\n",
      "child <__main__.MCTS_agent.<locals>.State object at 0x11da38df0>\n",
      "child <__main__.MCTS_agent.<locals>.State object at 0x11da38fd0>\n",
      "child <__main__.MCTS_agent.<locals>.State object at 0x11da39060>\n",
      "child <__main__.MCTS_agent.<locals>.State object at 0x11da39150>\n",
      "child <__main__.MCTS_agent.<locals>.State object at 0x11da39120>\n",
      "child <__main__.MCTS_agent.<locals>.State object at 0x11da39210>\n",
      "24718\n",
      "observation: {'remainingOverageTime': 59.999798999999996, 'mark': 2, 'step': 5, 'board': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 1, 2, 0]}\n",
      "board: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 1, 2, 0]\n",
      "mark: 2\n",
      "config: {'episodeSteps': 1000, 'actTimeout': 2, 'runTimeout': 1200, 'columns': 7, 'rows': 6, 'inarow': 4, 'agentTimeout': 60, 'timeout': 2}\n",
      "child <__main__.MCTS_agent.<locals>.State object at 0x10fef7be0>\n",
      "child <__main__.MCTS_agent.<locals>.State object at 0x10fef7e20>\n",
      "child <__main__.MCTS_agent.<locals>.State object at 0x10fe2c340>\n",
      "child <__main__.MCTS_agent.<locals>.State object at 0x10fe2c3a0>\n",
      "child <__main__.MCTS_agent.<locals>.State object at 0x10fe2c580>\n",
      "child <__main__.MCTS_agent.<locals>.State object at 0x10fe2c4f0>\n",
      "child <__main__.MCTS_agent.<locals>.State object at 0x10fe2c820>\n",
      "25775\n",
      "observation: {'remainingOverageTime': 59.999822, 'step': 6, 'board': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 1, 1, 2, 0], 'mark': 1}\n",
      "board: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 1, 1, 2, 0]\n",
      "mark: 1\n",
      "config: {'episodeSteps': 1000, 'actTimeout': 2, 'runTimeout': 1200, 'columns': 7, 'rows': 6, 'inarow': 4, 'agentTimeout': 60, 'timeout': 2}\n",
      "child <__main__.MCTS_agent.<locals>.State object at 0x11d72aef0>\n",
      "child <__main__.MCTS_agent.<locals>.State object at 0x11d72afb0>\n",
      "child <__main__.MCTS_agent.<locals>.State object at 0x11d72b280>\n",
      "child <__main__.MCTS_agent.<locals>.State object at 0x11d72b340>\n",
      "child <__main__.MCTS_agent.<locals>.State object at 0x11d72b520>\n",
      "child <__main__.MCTS_agent.<locals>.State object at 0x11d72b1c0>\n",
      "child <__main__.MCTS_agent.<locals>.State object at 0x11d72b400>\n",
      "27105\n",
      "observation: {'remainingOverageTime': 59.972007, 'mark': 2, 'step': 7, 'board': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 1, 1, 2, 0]}\n",
      "board: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 1, 1, 2, 0]\n",
      "mark: 2\n",
      "config: {'episodeSteps': 1000, 'actTimeout': 2, 'runTimeout': 1200, 'columns': 7, 'rows': 6, 'inarow': 4, 'agentTimeout': 60, 'timeout': 2}\n",
      "child <__main__.MCTS_agent.<locals>.State object at 0x12e8993f0>\n",
      "child <__main__.MCTS_agent.<locals>.State object at 0x12e8996c0>\n",
      "child <__main__.MCTS_agent.<locals>.State object at 0x12e8998d0>\n",
      "child <__main__.MCTS_agent.<locals>.State object at 0x12e899b10>\n",
      "child <__main__.MCTS_agent.<locals>.State object at 0x12e899a80>\n",
      "child <__main__.MCTS_agent.<locals>.State object at 0x12e899de0>\n",
      "child <__main__.MCTS_agent.<locals>.State object at 0x12e899c90>\n",
      "29543\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "try:\n",
    "    del current_state\n",
    "except:\n",
    "    pass\n",
    "\n",
    "env.run([MCTS_agent, MCTS_agent])\n",
    "print(\"Success!\" if env.state[0].status == env.state[1].status == \"DONE\" else \"Failed...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate your agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RWM edit - kept dividing by zero...\n",
    "# -1 = always loss, +1 = always win, ~0 = evens\n",
    "\n",
    "def mean_reward(rewards):\n",
    "    avg = sum(r[0] for r in rewards) / len(rewards)\n",
    "    num_losses = sum(-r[0] for r in rewards if r[0] == -1)\n",
    "\n",
    "    print_string = f\"Score = {avg}, N = {len(rewards)}, losses = {num_losses}\"\n",
    "\n",
    "    return print_string, avg\n",
    "\n",
    "# Run multiple episodes to estimate its performance.\n",
    "iterations = 1\n",
    "\n",
    "# RWM tests\n",
    "print(\"BENCHMARK - Negamax vs Random:\", mean_reward(evaluate(\"connectx\", [\"negamax\", \"random\"], num_episodes = iterations))[0])\n",
    "print(\"TEST - Random vs Random:\", mean_reward(evaluate(\"connectx\", [\"random\", \"random\"], num_episodes = iterations))[0])\n",
    "\n",
    "# RWM edit, old = 20 20 5 5\n",
    "\n",
    "print(\"My Agent vs Random Agent:\", mean_reward(evaluate(\"connectx\", [MCTS_agent, \"random\"], num_episodes = iterations))[0])\n",
    "# print(\"Random Agent vs My Agent:\", mean_reward(evaluate(\"connectx\", [\"random\", MCTS_agent], num_episodes = iterations))[0])\n",
    "# print(\"My Agent vs Negamax Agent:\", mean_reward(evaluate(\"connectx\", [MCTS_agent, \"negamax\"], num_episodes = iterations))[0])\n",
    "# print(\"Negamax Agent vs My Agent:\", mean_reward(evaluate(\"connectx\", [\"negamax\", MCTS_agent], num_episodes = iterations))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to 50:50?\n",
    "rel_iterations = 10\n",
    "print(\"TEST - Random vs Random:\", mean_reward(evaluate(\"connectx\", [\"random\", \"random\"], num_episodes = 5 * rel_iterations))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rel_iterations = 100\n",
    "# print(\"TEST - Random vs Random:\", mean_reward(evaluate(\"connectx\", [\"random\", \"random\"], num_episodes = 5 * rel_iterations))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # how long before NEGAMAX loses to RANDOM?\n",
    "\n",
    "# iterations = (2, 5, 10, 25, 50, 100) // 10 + 2\n",
    "# index = 1   # for plotting\n",
    "# MCTS_first = []\n",
    "# MCTS_second = []\n",
    "# time_first = []\n",
    "# time_second = []\n",
    "\n",
    "# for i in iterations:\n",
    "#     start1 = time.time()\n",
    "#     reward_first = mean_reward(evaluate(\"connectx\", [\"negamax\", \"random\"], num_episodes = i))[1]\n",
    "#     time_first.append(time.time() - start1)\n",
    "\n",
    "#     start2 = time.time()\n",
    "#     reward_second = mean_reward(evaluate(\"connectx\", [\"random\", \"negamax\"], num_episodes = i))[1]\n",
    "#     time_second.append(time.time() - start2)\n",
    "\n",
    "#     print(\"My Agent vs Negamax Agent:\", reward_first)\n",
    "#     print(\"Negamax Agent vs My Agent:\", reward_second)\n",
    "#     print(\"*\"*58)\n",
    "\n",
    "#     MCTS_first.append(reward_first)\n",
    "#     MCTS_second.append(reward_second)\n",
    "\n",
    "#     fig, ax = plt.subplots(2, 2, figsize=(9, 6))\n",
    "\n",
    "#     ax[0][0].plot(iterations[:index], MCTS_first, label=\"Negamax 1st\", color = 'cyan', linewidth=1.5)\n",
    "#     ax[0][1].plot(iterations[:index], MCTS_second, label=\"Negamax 2nd\", color = 'orange', linewidth=1.5)\n",
    "\n",
    "#     ax[1][0].plot(iterations[:index], time_first, color = 'cyan', linewidth=1.5)\n",
    "#     ax[1][1].plot(iterations[:index], time_second, color = 'orange', linewidth=1.5)\n",
    "\n",
    "\n",
    "#     (a.set_xlabel(\"#iterations\") for a in ax)\n",
    "#     ax[0][0].set_ylabel(\"Score (+1 = perfect)\")\n",
    "#     ax[1][0].set_ylabel(\"Comp time on Mac (seconds)\")\n",
    "\n",
    "#     lines_labels = [ax.get_legend_handles_labels() for ax in fig.axes]\n",
    "#     lines, labels = [sum(lol, []) for lol in zip(*lines_labels)]\n",
    "#     fig.legend(lines, labels, loc='upper right')\n",
    "\n",
    "#     plt.show()\n",
    "    \n",
    "#     print(\"*\"*58)\n",
    "\n",
    "#     index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how long before MCTS loses to NEGAMAX?\n",
    "from IPython.display import clear_output\n",
    "\n",
    "iterations = [2, 5, 10, 25, 50, 100]\n",
    "index = 1   # for plotting\n",
    "MCTS_first = []\n",
    "MCTS_second = []\n",
    "time_first = []\n",
    "time_second = []\n",
    "\n",
    "start_global = time.time()\n",
    "\n",
    "for i in iterations:\n",
    "    start1 = time.time()\n",
    "    reward_first = mean_reward(evaluate(\"connectx\", [MCTS_agent, \"negamax\"], num_episodes = i))[1]\n",
    "    time_first.append(time.time() - start1)\n",
    "\n",
    "    start2 = time.time()\n",
    "    reward_second = mean_reward(evaluate(\"connectx\", [\"negamax\", MCTS_agent], num_episodes = i))[1]\n",
    "    time_second.append(time.time() - start2)\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    print(\"My Agent vs Negamax Agent:\", reward_first)\n",
    "    print(\"Negamax Agent vs My Agent:\", reward_second)\n",
    "    print(\"N =\", i)\n",
    "    print(\"Avg +/- 1SD comp time per episode\", \n",
    "            np.mean( ( (np.array( (time_first) ) + np.array( (time_second) ) ) / np.array(2 * iterations[:index]))),\n",
    "            \"+/-\",\n",
    "            np.std( np.arr)\n",
    "            np.std( ( (np.array( (time_first) ) + np.array( (time_second) ) ) / np.array(2 * iterations[:index]))),\n",
    "            \"seconds\")\n",
    "    \n",
    "    print(\"Time elapsed =\", (time.time() - start_global) / 60, \"minutes\")\n",
    "    print(\"*\"*58)\n",
    "\n",
    "    MCTS_first.append(reward_first)\n",
    "    MCTS_second.append(reward_second)\n",
    "\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(9, 6))\n",
    "\n",
    "    ax[0][0].plot(iterations[:index], MCTS_first, 'o-', label=\"MCTS 1st\", color = 'blue', linewidth=1.5, markersize=3)\n",
    "    ax[0][1].plot(iterations[:index], MCTS_second, 'o-', label=\"MCTS 2nd\", color = 'red', linewidth=1.5, markersize=3)\n",
    "\n",
    "    ax[1][0].plot(iterations[:index], time_first, 'o-', color = 'blue', linewidth=1.5, markersize=3)\n",
    "    ax[1][1].plot(iterations[:index], time_second, 'o-', color = 'red', linewidth=1.5, markersize=3)\n",
    "\n",
    "    ax[1][0].set_xlabel(\"#iterations\")\n",
    "    ax[1][1].set_xlabel(\"#iterations\")\n",
    "\n",
    "    ax[0][0].set_ylabel(\"Score (+1 = perfect)\")\n",
    "    ax[1][0].set_ylabel(\"Comp time on Mac (seconds)\")\n",
    "\n",
    "    lines_labels = [ax.get_legend_handles_labels() for ax in fig.axes]\n",
    "    lines, labels = [sum(lol, []) for lol in zip(*lines_labels)]\n",
    "    fig.legend(lines, labels, loc='upper right')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"*\"*58)\n",
    "\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
