{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo Tree Search (MCTS)\n",
    "This is an agent that plays with UCT-MCTS.  \n",
    "Code is highly commented to be readable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# ConnectX environment was defined in v0.1.6\n",
    "from kaggle_environments import evaluate, make, utils\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "# RWM added\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create ConnectX Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episodeSteps': 1000, 'actTimeout': 2, 'runTimeout': 1200, 'columns': 7, 'rows': 6, 'inarow': 4, 'agentTimeout': 60, 'timeout': 2}\n"
     ]
    }
   ],
   "source": [
    "env = make(\"connectx\", debug=True)\n",
    "configuration = env.configuration\n",
    "print(configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MCTS_agent(observation, configuration):\n",
    "    \"\"\"\n",
    "    Connect X agent based on MCTS.\n",
    "    \"\"\"\n",
    "    import random\n",
    "    import math\n",
    "    import time\n",
    "    global current_state  # so tree can be recycled\n",
    "\n",
    "    init_time = time.time()\n",
    "    EMPTY = 0\n",
    "    T_max = configuration.timeout # time per move, left some overhead - RWM, old offset -0.34\n",
    "    Cp_default = 1\n",
    "\n",
    "    def play(board, column, mark, config):\n",
    "        \"\"\" Plays a move. Taken from the Kaggle environment. \"\"\"\n",
    "        columns = config.columns\n",
    "        rows = config.rows\n",
    "        row = max([r for r in range(rows) if board[column + (r * columns)] == EMPTY])\n",
    "        board[column + (row * columns)] = mark\n",
    "\n",
    "    def is_win(board, column, mark, config):\n",
    "        \"\"\" Checks for a win. Taken from the Kaggle environment. \"\"\"\n",
    "        columns = config.columns\n",
    "        rows = config.rows\n",
    "\n",
    "        # RWM edit\n",
    "        inarow = config.inarow - 1\n",
    "\n",
    "        # Connect3 to speed up testing?\n",
    "        # inarow = 3 - 1\n",
    "\n",
    "        row = min([r for r in range(rows) if board[column + (r * columns)] == mark])\n",
    "\n",
    "        def count(offset_row, offset_column):\n",
    "            for i in range(1, inarow + 1):\n",
    "                r = row + offset_row * i\n",
    "                c = column + offset_column * i\n",
    "                if (\n",
    "                        r < 0\n",
    "                        or r >= rows\n",
    "                        or c < 0\n",
    "                        or c >= columns\n",
    "                        or board[c + (r * columns)] != mark\n",
    "                ):\n",
    "                    return i - 1\n",
    "            return inarow\n",
    "\n",
    "        return (\n",
    "                count(1, 0) >= inarow  # vertical.\n",
    "                or (count(0, 1) + count(0, -1)) >= inarow  # horizontal.\n",
    "                or (count(-1, -1) + count(1, 1)) >= inarow  # top left diagonal.\n",
    "                or (count(-1, 1) + count(1, -1)) >= inarow  # top right diagonal.\n",
    "        )\n",
    "\n",
    "    def is_tie(board):\n",
    "        \"\"\" Checks if a tie occured. \"\"\"\n",
    "        return not(any(mark == EMPTY for mark in board))\n",
    "\n",
    "    def check_finish_and_score(board, column, mark, config):\n",
    "        \"\"\" Returns a tuple where the first argument states whether game is finished and second argument returns score if game has finished. \"\"\"\n",
    "        if is_win(board, column, mark, config):\n",
    "            return (True, 1)\n",
    "        if is_tie(board):\n",
    "            # RWM - default tie score = 0.5 - what if we change this? ie, punish draws to promote aggressive play?\n",
    "            return (True, 0.1)\n",
    "        else:\n",
    "            return (False, None)\n",
    "\n",
    "    def uct_score(node_total_score, node_total_visits, parent_total_visits, Cp=Cp_default):\n",
    "        \"\"\" UCB1 calculation. \"\"\"\n",
    "        if node_total_visits == 0:\n",
    "            return math.inf\n",
    "        return node_total_score / node_total_visits + Cp * math.sqrt(\n",
    "            2 * math.log(parent_total_visits) / node_total_visits)\n",
    "\n",
    "    def opponent_mark(mark):\n",
    "        \"\"\" The mark indicates which player is active - player 1 or player 2. \"\"\"\n",
    "        return 3 - mark\n",
    "\n",
    "    def opponent_score(score):\n",
    "        \"\"\" To backpropagate scores on the tree. \"\"\"\n",
    "        return 1 - score\n",
    "\n",
    "    def random_action(board, config):\n",
    "        \"\"\" Returns a random legal action (from the open columns). \"\"\"\n",
    "        return random.choice([c for c in range(config.columns) if board[c] == EMPTY])\n",
    "\n",
    "    def default_policy_simulation(board, mark, config):\n",
    "        \"\"\"\n",
    "        Run a random play simulation. Starting state is assumed to be a non-terminal state.\n",
    "        Returns score of the game for the player with the given mark.\n",
    "        \"\"\"\n",
    "        original_mark = mark\n",
    "        board = board.copy()\n",
    "        column = random_action(board, config)\n",
    "        play(board, column, mark, config)\n",
    "        is_finish, score = check_finish_and_score(board, column, mark, config)\n",
    "        while not is_finish:\n",
    "            mark = opponent_mark(mark)\n",
    "            column = random_action(board, config)\n",
    "            play(board, column, mark, config)\n",
    "            is_finish, score = check_finish_and_score(board, column, mark, config)\n",
    "        if mark == original_mark:\n",
    "            return score\n",
    "        return opponent_score(score)\n",
    "    \n",
    "    def find_action_taken_by_opponent(new_board, old_board, config):\n",
    "        \"\"\" Given a new board state and a previous one, finds which move was taken. Used for recycling tree between moves. \"\"\"\n",
    "        for i, piece in enumerate(new_board):\n",
    "            if piece != old_board[i]:\n",
    "                return i % config.columns\n",
    "        return -1  # shouldn't get here\n",
    "\n",
    "    class State():\n",
    "        \"\"\" \n",
    "        A class that represents nodes in the game tree.\n",
    "        \n",
    "        \"\"\"\n",
    "        def __init__(self, board, mark, config, parent=None, is_terminal=False, terminal_score=None, action_taken=None):\n",
    "            self.board = board.copy()\n",
    "            self.mark = mark\n",
    "            self.config = config\n",
    "            self.children = []\n",
    "            self.parent = parent\n",
    "            self.node_total_score = 0\n",
    "            self.node_total_visits = 0\n",
    "            self.available_moves = [c for c in range(config.columns) if board[c] == EMPTY]\n",
    "            self.expandable_moves = self.available_moves.copy()\n",
    "            self.is_terminal = is_terminal\n",
    "            self.terminal_score = terminal_score\n",
    "            self.action_taken = action_taken\n",
    "\n",
    "        def is_expandable(self):\n",
    "            \"\"\" Checks if the node has unexplored children. \"\"\"\n",
    "            return (not self.is_terminal) and (len(self.expandable_moves) > 0)\n",
    "\n",
    "        def expand_and_simulate_child(self):\n",
    "            \"\"\" Expands a random move from the legal unexplored moves, and runs a simulation of it \n",
    "            (Expansion + Simulation + Backpropagation stages in the MCTS algorithm description). \"\"\"\n",
    "            column = random.choice(self.expandable_moves)\n",
    "            child_board = self.board.copy()\n",
    "            play(child_board, column, self.mark, self.config)\n",
    "            is_terminal, terminal_score = check_finish_and_score(child_board, column, self.mark, self.config)\n",
    "            self.children.append(State(child_board, opponent_mark(self.mark),\n",
    "                                       self.config, parent=self,\n",
    "                                       is_terminal=is_terminal,\n",
    "                                       terminal_score=terminal_score,\n",
    "                                       action_taken=column\n",
    "                                       ))\n",
    "            simulation_score = self.children[-1].simulate()\n",
    "            self.children[-1].backpropagate(simulation_score)\n",
    "            self.expandable_moves.remove(column)\n",
    "\n",
    "        def choose_strongest_child(self, Cp):\n",
    "            \"\"\"\n",
    "            Chooses child that maximizes UCB1 score (Selection stage in the MCTS algorithm description).\n",
    "            \"\"\"\n",
    "            children_scores = [uct_score(child.node_total_score,\n",
    "                                         child.node_total_visits,\n",
    "                                         self.node_total_visits,\n",
    "                                         Cp) for child in self.children]\n",
    "            max_score = max(children_scores)\n",
    "            best_child_index = children_scores.index(max_score)\n",
    "            return self.children[best_child_index]\n",
    "            \n",
    "        def choose_play_child(self):\n",
    "            \"\"\" Choose child with maximum total score.\"\"\"\n",
    "            children_scores = [child.node_total_score for child in self.children]\n",
    "            max_score = max(children_scores)\n",
    "            best_child_index = children_scores.index(max_score)\n",
    "            return self.children[best_child_index]\n",
    "\n",
    "        def tree_single_run(self):\n",
    "            \"\"\"\n",
    "            A single iteration of the 4 stages of the MCTS algorithm.\n",
    "            \"\"\"\n",
    "            if self.is_terminal:\n",
    "                self.backpropagate(self.terminal_score)\n",
    "                return\n",
    "            if self.is_expandable():\n",
    "                self.expand_and_simulate_child()\n",
    "                return\n",
    "            self.choose_strongest_child(Cp_default).tree_single_run()\n",
    "\n",
    "        def simulate(self):\n",
    "            \"\"\"\n",
    "            Runs a simulation from the current state. \n",
    "            This method is used to simulate a game after move of current player, so if a terminal state was reached,\n",
    "            the score would belong to the current player who made the move.\n",
    "            But otherwise the score received from the simulation run is the opponent's score and thus needs to be flipped with the function opponent_score().            \n",
    "            \"\"\"\n",
    "            if self.is_terminal:\n",
    "                return self.terminal_score\n",
    "            return opponent_score(default_policy_simulation(self.board, self.mark, self.config))\n",
    "\n",
    "        def backpropagate(self, simulation_score):\n",
    "            \"\"\"\n",
    "            Backpropagates score and visit count to parents.\n",
    "            \"\"\"\n",
    "            self.node_total_score += simulation_score\n",
    "            self.node_total_visits += 1\n",
    "            if self.parent is not None:\n",
    "                self.parent.backpropagate(opponent_score(simulation_score))\n",
    "                \n",
    "        def choose_child_via_action(self, action):\n",
    "            \"\"\" Choose child given the action taken from the state. Used for recycling of tree. \"\"\"\n",
    "\n",
    "            for child in self.children:\n",
    "                \n",
    "                # RWM test\n",
    "                print(\"child\", child)\n",
    "\n",
    "                if child.action_taken == action:\n",
    "                    return child\n",
    "            return None\n",
    "\n",
    "    board = observation.board\n",
    "    mark = observation.mark\n",
    "    \n",
    "    print(\"observation:\", observation)\n",
    "    print(\"board:\", board)\n",
    "    print(\"mark:\", mark)\n",
    "    print(\"config:\", configuration)\n",
    "    \n",
    "\n",
    "    # If current_state already exists, recycle it based on action taken by opponent\n",
    "    try:  \n",
    "        current_state = current_state.choose_child_via_action(\n",
    "            find_action_taken_by_opponent(board, current_state.board, configuration))\n",
    "        current_state.parent = None  # make current_state the root node, dereference parents and siblings\n",
    "        \n",
    "    except:  # new game or other error in recycling attempt due to Kaggle mechanism\n",
    "        current_state = State(board, mark,  # This state is considered after the opponent's move\n",
    "                              configuration, parent=None, is_terminal=False, terminal_score=None, action_taken=None)\n",
    "   \n",
    "    # Run MCTS iterations until time limit is reached.\n",
    "    while time.time() - init_time <= T_max:\n",
    "        current_state.tree_single_run()\n",
    "        \n",
    "    current_state = current_state.choose_play_child()\n",
    "    return current_state.action_taken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check agent validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation: {'remainingOverageTime': 60, 'step': 0, 'board': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mark': 1}\n",
      "board: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "mark: 1\n",
      "config: {'episodeSteps': 1000, 'actTimeout': 2, 'runTimeout': 1200, 'columns': 7, 'rows': 6, 'inarow': 4, 'agentTimeout': 60, 'timeout': 2}\n",
      "observation: {'remainingOverageTime': 60, 'mark': 2, 'step': 1, 'board': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]}\n",
      "board: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      "mark: 2\n",
      "config: {'episodeSteps': 1000, 'actTimeout': 2, 'runTimeout': 1200, 'columns': 7, 'rows': 6, 'inarow': 4, 'agentTimeout': 60, 'timeout': 2}\n",
      "children [<__main__.MCTS_agent.<locals>.State object at 0x11e689150>, <__main__.MCTS_agent.<locals>.State object at 0x11e688fa0>, <__main__.MCTS_agent.<locals>.State object at 0x11e689060>, <__main__.MCTS_agent.<locals>.State object at 0x11e689330>, <__main__.MCTS_agent.<locals>.State object at 0x11e688df0>, <__main__.MCTS_agent.<locals>.State object at 0x11e689480>, <__main__.MCTS_agent.<locals>.State object at 0x10fe37c70>]\n",
      "observation: {'remainingOverageTime': 59.999918, 'step': 2, 'board': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], 'mark': 1}\n",
      "board: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      "mark: 1\n",
      "config: {'episodeSteps': 1000, 'actTimeout': 2, 'runTimeout': 1200, 'columns': 7, 'rows': 6, 'inarow': 4, 'agentTimeout': 60, 'timeout': 2}\n",
      "children [<__main__.MCTS_agent.<locals>.State object at 0x12ed12b30>, <__main__.MCTS_agent.<locals>.State object at 0x12ed12da0>, <__main__.MCTS_agent.<locals>.State object at 0x12ed12e00>, <__main__.MCTS_agent.<locals>.State object at 0x12ed13190>, <__main__.MCTS_agent.<locals>.State object at 0x12ed131c0>, <__main__.MCTS_agent.<locals>.State object at 0x12ed135b0>, <__main__.MCTS_agent.<locals>.State object at 0x11e689e40>]\n",
      "observation: {'remainingOverageTime': 59.999883, 'mark': 2, 'step': 3, 'board': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]}\n",
      "board: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      "mark: 2\n",
      "config: {'episodeSteps': 1000, 'actTimeout': 2, 'runTimeout': 1200, 'columns': 7, 'rows': 6, 'inarow': 4, 'agentTimeout': 60, 'timeout': 2}\n",
      "children [<__main__.MCTS_agent.<locals>.State object at 0x12de1bfd0>, <__main__.MCTS_agent.<locals>.State object at 0x12de1b2e0>, <__main__.MCTS_agent.<locals>.State object at 0x12e8e44c0>, <__main__.MCTS_agent.<locals>.State object at 0x12e8e45e0>, <__main__.MCTS_agent.<locals>.State object at 0x12e8e4670>, <__main__.MCTS_agent.<locals>.State object at 0x12e8e4790>, <__main__.MCTS_agent.<locals>.State object at 0x12e8e4e80>]\n",
      "observation: {'remainingOverageTime': 59.9998, 'step': 4, 'board': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0], 'mark': 1}\n",
      "board: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0]\n",
      "mark: 1\n",
      "config: {'episodeSteps': 1000, 'actTimeout': 2, 'runTimeout': 1200, 'columns': 7, 'rows': 6, 'inarow': 4, 'agentTimeout': 60, 'timeout': 2}\n",
      "children [<__main__.MCTS_agent.<locals>.State object at 0x12daa4070>, <__main__.MCTS_agent.<locals>.State object at 0x12daa4430>, <__main__.MCTS_agent.<locals>.State object at 0x12daa4eb0>, <__main__.MCTS_agent.<locals>.State object at 0x12daa77f0>, <__main__.MCTS_agent.<locals>.State object at 0x12daa7670>, <__main__.MCTS_agent.<locals>.State object at 0x12daa50c0>, <__main__.MCTS_agent.<locals>.State object at 0x12daa7190>]\n",
      "observation: {'remainingOverageTime': 59.999765, 'mark': 2, 'step': 5, 'board': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 1, 2, 0, 0]}\n",
      "board: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 1, 2, 0, 0]\n",
      "mark: 2\n",
      "config: {'episodeSteps': 1000, 'actTimeout': 2, 'runTimeout': 1200, 'columns': 7, 'rows': 6, 'inarow': 4, 'agentTimeout': 60, 'timeout': 2}\n",
      "children [<__main__.MCTS_agent.<locals>.State object at 0x12fe6e2f0>, <__main__.MCTS_agent.<locals>.State object at 0x12fe6e770>, <__main__.MCTS_agent.<locals>.State object at 0x12fe6e920>, <__main__.MCTS_agent.<locals>.State object at 0x12fe6ed10>, <__main__.MCTS_agent.<locals>.State object at 0x12fe6ed70>, <__main__.MCTS_agent.<locals>.State object at 0x12daa72b0>, <__main__.MCTS_agent.<locals>.State object at 0x12fe6efb0>]\n",
      "observation: {'remainingOverageTime': 59.999718, 'step': 6, 'board': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 1, 2, 0, 0], 'mark': 1}\n",
      "board: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 1, 2, 0, 0]\n",
      "mark: 1\n",
      "config: {'episodeSteps': 1000, 'actTimeout': 2, 'runTimeout': 1200, 'columns': 7, 'rows': 6, 'inarow': 4, 'agentTimeout': 60, 'timeout': 2}\n",
      "children [<__main__.MCTS_agent.<locals>.State object at 0x13e07c220>, <__main__.MCTS_agent.<locals>.State object at 0x13e07c0a0>, <__main__.MCTS_agent.<locals>.State object at 0x13e07c400>, <__main__.MCTS_agent.<locals>.State object at 0x13e07c5e0>, <__main__.MCTS_agent.<locals>.State object at 0x13e07c580>, <__main__.MCTS_agent.<locals>.State object at 0x13e07c700>, <__main__.MCTS_agent.<locals>.State object at 0x12f93b9a0>]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m      5\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m env\u001b[39m.\u001b[39mrun([MCTS_agent, MCTS_agent])\n\u001b[1;32m      8\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mSuccess!\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m env\u001b[39m.\u001b[39mstate[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m env\u001b[39m.\u001b[39mstate[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mDONE\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mFailed...\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/kaggle_environments/core.py:267\u001b[0m, in \u001b[0;36mEnvironment.run\u001b[0;34m(self, agents)\u001b[0m\n\u001b[1;32m    265\u001b[0m start \u001b[39m=\u001b[39m perf_counter()\n\u001b[1;32m    266\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdone \u001b[39mand\u001b[39;00m perf_counter() \u001b[39m-\u001b[39m start \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfiguration\u001b[39m.\u001b[39mrunTimeout:\n\u001b[0;32m--> 267\u001b[0m     actions, logs \u001b[39m=\u001b[39m runner\u001b[39m.\u001b[39;49mact()\n\u001b[1;32m    268\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep(actions, logs)\n\u001b[1;32m    269\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdone \u001b[39mand\u001b[39;00m perf_counter() \u001b[39m-\u001b[39m start \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfiguration\u001b[39m.\u001b[39mrunTimeout:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/kaggle_environments/core.py:697\u001b[0m, in \u001b[0;36mEnvironment.__agent_runner.<locals>.act\u001b[0;34m(none_action)\u001b[0m\n\u001b[1;32m    695\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool\u001b[39m.\u001b[39mmap(act_agent, act_args)\n\u001b[1;32m    696\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 697\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(\u001b[39mmap\u001b[39;49m(act_agent, act_args))\n\u001b[1;32m    699\u001b[0m \u001b[39m# results is a list of tuples where the first element is an agent action and the second is the agent log\u001b[39;00m\n\u001b[1;32m    700\u001b[0m \u001b[39m# This destructures into two lists, a list of actions and a list of logs.\u001b[39;00m\n\u001b[1;32m    701\u001b[0m actions, logs \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mresults)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/kaggle_environments/core.py:118\u001b[0m, in \u001b[0;36mact_agent\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[39mreturn\u001b[39;00m none_action, {}\n\u001b[1;32m    117\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m     \u001b[39mreturn\u001b[39;00m agent\u001b[39m.\u001b[39;49mact(state[\u001b[39m\"\u001b[39;49m\u001b[39mobservation\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/kaggle_environments/agent.py:159\u001b[0m, in \u001b[0;36mAgent.act\u001b[0;34m(self, observation)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     start \u001b[39m=\u001b[39m perf_counter()\n\u001b[0;32m--> 159\u001b[0m     action \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49magent(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    160\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    161\u001b[0m     traceback\u001b[39m.\u001b[39mprint_exc(file\u001b[39m=\u001b[39merr_buffer)\n",
      "Cell \u001b[0;32mIn [7], line 237\u001b[0m, in \u001b[0;36mMCTS_agent\u001b[0;34m(observation, configuration)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[39m# Run MCTS iterations until time limit is reached.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[39mwhile\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m init_time \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m T_max:\n\u001b[0;32m--> 237\u001b[0m     current_state\u001b[39m.\u001b[39;49mtree_single_run()\n\u001b[1;32m    239\u001b[0m current_state \u001b[39m=\u001b[39m current_state\u001b[39m.\u001b[39mchoose_play_child()\n\u001b[1;32m    240\u001b[0m \u001b[39mreturn\u001b[39;00m current_state\u001b[39m.\u001b[39maction_taken\n",
      "Cell \u001b[0;32mIn [7], line 184\u001b[0m, in \u001b[0;36mMCTS_agent.<locals>.State.tree_single_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexpand_and_simulate_child()\n\u001b[1;32m    183\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 184\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchoose_strongest_child(Cp_default)\u001b[39m.\u001b[39;49mtree_single_run()\n",
      "Cell \u001b[0;32mIn [7], line 184\u001b[0m, in \u001b[0;36mMCTS_agent.<locals>.State.tree_single_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexpand_and_simulate_child()\n\u001b[1;32m    183\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 184\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchoose_strongest_child(Cp_default)\u001b[39m.\u001b[39;49mtree_single_run()\n",
      "    \u001b[0;31m[... skipping similar frames: MCTS_agent.<locals>.State.tree_single_run at line 184 (2 times)]\u001b[0m\n",
      "Cell \u001b[0;32mIn [7], line 184\u001b[0m, in \u001b[0;36mMCTS_agent.<locals>.State.tree_single_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexpand_and_simulate_child()\n\u001b[1;32m    183\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 184\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchoose_strongest_child(Cp_default)\u001b[39m.\u001b[39;49mtree_single_run()\n",
      "Cell \u001b[0;32mIn [7], line 182\u001b[0m, in \u001b[0;36mMCTS_agent.<locals>.State.tree_single_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_expandable():\n\u001b[0;32m--> 182\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexpand_and_simulate_child()\n\u001b[1;32m    183\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchoose_strongest_child(Cp_default)\u001b[39m.\u001b[39mtree_single_run()\n",
      "Cell \u001b[0;32mIn [7], line 151\u001b[0m, in \u001b[0;36mMCTS_agent.<locals>.State.expand_and_simulate_child\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    144\u001b[0m is_terminal, terminal_score \u001b[39m=\u001b[39m check_finish_and_score(child_board, column, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmark, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig)\n\u001b[1;32m    145\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren\u001b[39m.\u001b[39mappend(State(child_board, opponent_mark(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmark),\n\u001b[1;32m    146\u001b[0m                            \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig, parent\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m,\n\u001b[1;32m    147\u001b[0m                            is_terminal\u001b[39m=\u001b[39mis_terminal,\n\u001b[1;32m    148\u001b[0m                            terminal_score\u001b[39m=\u001b[39mterminal_score,\n\u001b[1;32m    149\u001b[0m                            action_taken\u001b[39m=\u001b[39mcolumn\n\u001b[1;32m    150\u001b[0m                            ))\n\u001b[0;32m--> 151\u001b[0m simulation_score \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchildren[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49msimulate()\n\u001b[1;32m    152\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mbackpropagate(simulation_score)\n\u001b[1;32m    153\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexpandable_moves\u001b[39m.\u001b[39mremove(column)\n",
      "Cell \u001b[0;32mIn [7], line 195\u001b[0m, in \u001b[0;36mMCTS_agent.<locals>.State.simulate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_terminal:\n\u001b[1;32m    194\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mterminal_score\n\u001b[0;32m--> 195\u001b[0m \u001b[39mreturn\u001b[39;00m opponent_score(default_policy_simulation(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mboard, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmark, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig))\n",
      "Cell \u001b[0;32mIn [7], line 98\u001b[0m, in \u001b[0;36mMCTS_agent.<locals>.default_policy_simulation\u001b[0;34m(board, mark, config)\u001b[0m\n\u001b[1;32m     96\u001b[0m column \u001b[39m=\u001b[39m random_action(board, config)\n\u001b[1;32m     97\u001b[0m play(board, column, mark, config)\n\u001b[0;32m---> 98\u001b[0m is_finish, score \u001b[39m=\u001b[39m check_finish_and_score(board, column, mark, config)\n\u001b[1;32m     99\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m is_finish:\n\u001b[1;32m    100\u001b[0m     mark \u001b[39m=\u001b[39m opponent_mark(mark)\n",
      "Cell \u001b[0;32mIn [7], line 62\u001b[0m, in \u001b[0;36mMCTS_agent.<locals>.check_finish_and_score\u001b[0;34m(board, column, mark, config)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_finish_and_score\u001b[39m(board, column, mark, config):\n\u001b[1;32m     61\u001b[0m     \u001b[39m\"\"\" Returns a tuple where the first argument states whether game is finished and second argument returns score if game has finished. \"\"\"\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m     \u001b[39mif\u001b[39;00m is_win(board, column, mark, config):\n\u001b[1;32m     63\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, \u001b[39m1\u001b[39m)\n\u001b[1;32m     64\u001b[0m     \u001b[39mif\u001b[39;00m is_tie(board):\n\u001b[1;32m     65\u001b[0m         \u001b[39m# RWM - default tie score = 0.5 - what if we change this? ie, punish draws to promote aggressive play?\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [7], line 22\u001b[0m, in \u001b[0;36mMCTS_agent.<locals>.is_win\u001b[0;34m(board, column, mark, config)\u001b[0m\n\u001b[1;32m     19\u001b[0m     row \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m([r \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(rows) \u001b[39mif\u001b[39;00m board[column \u001b[39m+\u001b[39m (r \u001b[39m*\u001b[39m columns)] \u001b[39m==\u001b[39m EMPTY])\n\u001b[1;32m     20\u001b[0m     board[column \u001b[39m+\u001b[39m (row \u001b[39m*\u001b[39m columns)] \u001b[39m=\u001b[39m mark\n\u001b[0;32m---> 22\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_win\u001b[39m(board, column, mark, config):\n\u001b[1;32m     23\u001b[0m     \u001b[39m\"\"\" Checks for a win. Taken from the Kaggle environment. \"\"\"\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     columns \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mcolumns\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "try:\n",
    "    del current_state\n",
    "except:\n",
    "    pass\n",
    "\n",
    "env.run([MCTS_agent, MCTS_agent])\n",
    "print(\"Success!\" if env.state[0].status == env.state[1].status == \"DONE\" else \"Failed...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate your agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RWM edit - kept dividing by zero...\n",
    "# -1 = always loss, +1 = always win, ~0 = evens\n",
    "\n",
    "def mean_reward(rewards):\n",
    "    avg = sum(r[0] for r in rewards) / len(rewards)\n",
    "    num_losses = sum(-r[0] for r in rewards if r[0] == -1)\n",
    "\n",
    "    print_string = f\"Score = {avg}, N = {len(rewards)}, losses = {num_losses}\"\n",
    "\n",
    "    return print_string, avg\n",
    "\n",
    "# Run multiple episodes to estimate its performance.\n",
    "iterations = 1\n",
    "\n",
    "# RWM tests\n",
    "print(\"BENCHMARK - Negamax vs Random:\", mean_reward(evaluate(\"connectx\", [\"negamax\", \"random\"], num_episodes = iterations))[0])\n",
    "print(\"TEST - Random vs Random:\", mean_reward(evaluate(\"connectx\", [\"random\", \"random\"], num_episodes = iterations))[0])\n",
    "\n",
    "# RWM edit, old = 20 20 5 5\n",
    "\n",
    "print(\"My Agent vs Random Agent:\", mean_reward(evaluate(\"connectx\", [MCTS_agent, \"random\"], num_episodes = iterations))[0])\n",
    "# print(\"Random Agent vs My Agent:\", mean_reward(evaluate(\"connectx\", [\"random\", MCTS_agent], num_episodes = iterations))[0])\n",
    "# print(\"My Agent vs Negamax Agent:\", mean_reward(evaluate(\"connectx\", [MCTS_agent, \"negamax\"], num_episodes = iterations))[0])\n",
    "# print(\"Negamax Agent vs My Agent:\", mean_reward(evaluate(\"connectx\", [\"negamax\", MCTS_agent], num_episodes = iterations))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to 50:50?\n",
    "rel_iterations = 10\n",
    "print(\"TEST - Random vs Random:\", mean_reward(evaluate(\"connectx\", [\"random\", \"random\"], num_episodes = 5 * rel_iterations))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rel_iterations = 100\n",
    "# print(\"TEST - Random vs Random:\", mean_reward(evaluate(\"connectx\", [\"random\", \"random\"], num_episodes = 5 * rel_iterations))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # how long before NEGAMAX loses to RANDOM?\n",
    "\n",
    "# iterations = (2, 5, 10, 25, 50, 100) // 10 + 2\n",
    "# index = 1   # for plotting\n",
    "# MCTS_first = []\n",
    "# MCTS_second = []\n",
    "# time_first = []\n",
    "# time_second = []\n",
    "\n",
    "# for i in iterations:\n",
    "#     start1 = time.time()\n",
    "#     reward_first = mean_reward(evaluate(\"connectx\", [\"negamax\", \"random\"], num_episodes = i))[1]\n",
    "#     time_first.append(time.time() - start1)\n",
    "\n",
    "#     start2 = time.time()\n",
    "#     reward_second = mean_reward(evaluate(\"connectx\", [\"random\", \"negamax\"], num_episodes = i))[1]\n",
    "#     time_second.append(time.time() - start2)\n",
    "\n",
    "#     print(\"My Agent vs Negamax Agent:\", reward_first)\n",
    "#     print(\"Negamax Agent vs My Agent:\", reward_second)\n",
    "#     print(\"*\"*58)\n",
    "\n",
    "#     MCTS_first.append(reward_first)\n",
    "#     MCTS_second.append(reward_second)\n",
    "\n",
    "#     fig, ax = plt.subplots(2, 2, figsize=(9, 6))\n",
    "\n",
    "#     ax[0][0].plot(iterations[:index], MCTS_first, label=\"Negamax 1st\", color = 'cyan', linewidth=1.5)\n",
    "#     ax[0][1].plot(iterations[:index], MCTS_second, label=\"Negamax 2nd\", color = 'orange', linewidth=1.5)\n",
    "\n",
    "#     ax[1][0].plot(iterations[:index], time_first, color = 'cyan', linewidth=1.5)\n",
    "#     ax[1][1].plot(iterations[:index], time_second, color = 'orange', linewidth=1.5)\n",
    "\n",
    "\n",
    "#     (a.set_xlabel(\"#iterations\") for a in ax)\n",
    "#     ax[0][0].set_ylabel(\"Score (+1 = perfect)\")\n",
    "#     ax[1][0].set_ylabel(\"Comp time on Mac (seconds)\")\n",
    "\n",
    "#     lines_labels = [ax.get_legend_handles_labels() for ax in fig.axes]\n",
    "#     lines, labels = [sum(lol, []) for lol in zip(*lines_labels)]\n",
    "#     fig.legend(lines, labels, loc='upper right')\n",
    "\n",
    "#     plt.show()\n",
    "    \n",
    "#     print(\"*\"*58)\n",
    "\n",
    "#     index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how long before MCTS loses to NEGAMAX?\n",
    "from IPython.display import clear_output\n",
    "\n",
    "iterations = [2, 5, 10, 25, 50, 100]\n",
    "index = 1   # for plotting\n",
    "MCTS_first = []\n",
    "MCTS_second = []\n",
    "time_first = []\n",
    "time_second = []\n",
    "\n",
    "start_global = time.time()\n",
    "\n",
    "for i in iterations:\n",
    "    start1 = time.time()\n",
    "    reward_first = mean_reward(evaluate(\"connectx\", [MCTS_agent, \"negamax\"], num_episodes = i))[1]\n",
    "    time_first.append(time.time() - start1)\n",
    "\n",
    "    start2 = time.time()\n",
    "    reward_second = mean_reward(evaluate(\"connectx\", [\"negamax\", MCTS_agent], num_episodes = i))[1]\n",
    "    time_second.append(time.time() - start2)\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    print(\"My Agent vs Negamax Agent:\", reward_first)\n",
    "    print(\"Negamax Agent vs My Agent:\", reward_second)\n",
    "    print(\"N =\", i)\n",
    "    print(\"Avg +/- 1SD comp time per episode\", \n",
    "            np.mean( ( (np.array( (time_first) ) + np.array( (time_second) ) ) / np.array(2 * iterations[:index]))),\n",
    "            \"+/-\",\n",
    "            np.std( np.arr)\n",
    "            np.std( ( (np.array( (time_first) ) + np.array( (time_second) ) ) / np.array(2 * iterations[:index]))),\n",
    "            \"seconds\")\n",
    "    \n",
    "    print(\"Time elapsed =\", (time.time() - start_global) / 60, \"minutes\")\n",
    "    print(\"*\"*58)\n",
    "\n",
    "    MCTS_first.append(reward_first)\n",
    "    MCTS_second.append(reward_second)\n",
    "\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(9, 6))\n",
    "\n",
    "    ax[0][0].plot(iterations[:index], MCTS_first, 'o-', label=\"MCTS 1st\", color = 'blue', linewidth=1.5, markersize=3)\n",
    "    ax[0][1].plot(iterations[:index], MCTS_second, 'o-', label=\"MCTS 2nd\", color = 'red', linewidth=1.5, markersize=3)\n",
    "\n",
    "    ax[1][0].plot(iterations[:index], time_first, 'o-', color = 'blue', linewidth=1.5, markersize=3)\n",
    "    ax[1][1].plot(iterations[:index], time_second, 'o-', color = 'red', linewidth=1.5, markersize=3)\n",
    "\n",
    "    ax[1][0].set_xlabel(\"#iterations\")\n",
    "    ax[1][1].set_xlabel(\"#iterations\")\n",
    "\n",
    "    ax[0][0].set_ylabel(\"Score (+1 = perfect)\")\n",
    "    ax[1][0].set_ylabel(\"Comp time on Mac (seconds)\")\n",
    "\n",
    "    lines_labels = [ax.get_legend_handles_labels() for ax in fig.axes]\n",
    "    lines, labels = [sum(lol, []) for lol in zip(*lines_labels)]\n",
    "    fig.legend(lines, labels, loc='upper right')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"*\"*58)\n",
    "\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
